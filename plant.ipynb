{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.enable_eager_execution(config=config)\n",
    "from tensorflow.contrib.data import shuffle_and_repeat, map_and_batch, prefetch_to_device, parallel_interleave\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = os.cpu_count()\n",
    "epochs=10\n",
    "batch=128\n",
    "shuffle_buff_size=5000\n",
    "height, width = 100, 100\n",
    "\n",
    "train_dir = \"train/\"\n",
    "classes = os.listdir(train_dir)\n",
    "classes = sorted(classes)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = {\n",
    "    'x': tf.FixedLenFeature([], dtype=tf.string, default_value=''),\n",
    "    'y': tf.FixedLenFeature([], tf.int64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(example, height, width,num_classes, img_features):\n",
    "    parsed = tf.parse_single_example(example, img_features)\n",
    "    image, label = parsed[\"x\"], parsed[\"y\"]\n",
    "    #print(label)\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_image(image)\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image,height,width)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    #augmentation\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    label = tf.one_hot(label, num_classes) \n",
    "    label = tf.cast(label, tf.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = \"train*.tfrecords\"\n",
    "files = tf.data.Dataset.list_files(file_pattern)\n",
    "dataset = tf.data.TFRecordDataset(files, num_parallel_reads=cores)\n",
    "\n",
    "dataset = dataset.apply(shuffle_and_repeat(shuffle_buff_size, epochs))\n",
    "dataset = dataset.apply(\n",
    "    map_and_batch(lambda x: parse_fn(x, height,width, num_classes, img_features), batch, num_parallel_batches=cores))\n",
    "dataset = dataset.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv2D(64,3, padding=\"same\", activation=\"relu\", input_shape=(height,width, 3)))\n",
    "model.add(layers.Conv2D(64,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(128,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(128,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(256,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(256,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(256,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(512,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(512,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(512,3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation=\"relu\"))\n",
    "model.add(layers.Dense(4096, activation=\"relu\"))\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, (x, y)) in enumerate(tf.contrib.eager.Iterator(dataset)):\n",
    "    #print(i, x, y)\n",
    "    loss, acc = model.train_on_batch(x,y)\n",
    "    print(loss, acc)\n",
    "    #print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test,y_test)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
